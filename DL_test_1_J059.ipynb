{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J059DLabtest1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scbadkas19/Deep-learning/blob/master/DL_test_1_J059.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX7eG_ZvCYbB",
        "colab_type": "text"
      },
      "source": [
        "Saurabh Badkas[J059]\n",
        "DL lab test1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfQpRrLz-hD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import pandas\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras import optimizers\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3lbEseKtBSh",
        "colab_type": "code",
        "outputId": "bdc8923c-53b3-413f-f199-e4ac170db1d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history=model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.2348 - acc: 0.9283 - val_loss: 0.1460 - val_acc: 0.9539\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0848 - acc: 0.9738 - val_loss: 0.0783 - val_acc: 0.9758\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0581 - acc: 0.9823 - val_loss: 0.1038 - val_acc: 0.9690\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0415 - acc: 0.9870 - val_loss: 0.0797 - val_acc: 0.9778\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0298 - acc: 0.9908 - val_loss: 0.0822 - val_acc: 0.9791\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0224 - acc: 0.9928 - val_loss: 0.0766 - val_acc: 0.9797\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0197 - acc: 0.9941 - val_loss: 0.0832 - val_acc: 0.9808\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0151 - acc: 0.9951 - val_loss: 0.0896 - val_acc: 0.9818\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0127 - acc: 0.9956 - val_loss: 0.0859 - val_acc: 0.9819\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0111 - acc: 0.9963 - val_loss: 0.0915 - val_acc: 0.9832\n",
            "Test loss: 0.091501376068523\n",
            "Test accuracy: 0.9832\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzxvYfLIxzax",
        "colab_type": "code",
        "outputId": "03252223-d3bd-497f-8fdc-fa00c98b3db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)\n",
        "\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0818 - val_acc: 0.9845\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0798 - val_acc: 0.9855\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0789 - val_acc: 0.9855\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0782 - val_acc: 0.9855\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0779 - val_acc: 0.9857\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0774 - val_acc: 0.9857\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0771 - val_acc: 0.9860\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0769 - val_acc: 0.9860\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 9.9201e-04 - acc: 0.9999 - val_loss: 0.0766 - val_acc: 0.9861\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 9.4020e-04 - acc: 0.9999 - val_loss: 0.0764 - val_acc: 0.9861\n",
            "Test loss: 0.07640222430073923\n",
            "Test accuracy: 0.9861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhHi5SE1x3bN",
        "colab_type": "code",
        "outputId": "080d6471-f109-4ec6-dba2-64ce7a871610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.0990 - val_acc: 0.9821\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0933 - val_acc: 0.9845\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0941 - val_acc: 0.9839\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.1045 - val_acc: 0.9821\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.1261 - val_acc: 0.9819\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.1151 - val_acc: 0.9829\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.1286 - val_acc: 0.9820\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0052 - acc: 0.9986 - val_loss: 0.1065 - val_acc: 0.9829\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.1316 - val_acc: 0.9827\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.1348 - val_acc: 0.9820\n",
            "Test loss: 0.1347563926177445\n",
            "Test accuracy: 0.982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqC0OdUMyDvV",
        "colab_type": "code",
        "outputId": "9c88531c-eb13-47fd-ddfa-7a804d06dc6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0316 - acc: 0.9957 - val_loss: 0.1140 - val_acc: 0.9867\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.1137 - val_acc: 0.9849\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 3.9998e-04 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9848\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 2.8840e-04 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9846\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 2.8461e-04 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9848\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 2.8242e-04 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9848\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 2.8096e-04 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9848\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7987e-04 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9849\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 2.7900e-04 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9852\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7829e-04 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9852\n",
            "Test loss: 0.11007211287122777\n",
            "Test accuracy: 0.9852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byDFsBzDyaOs",
        "colab_type": "code",
        "outputId": "7e9fed03-380f-4392-db71-926c20e48339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 2.7783e-04 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9852\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 2.7620e-04 - acc: 1.0000 - val_loss: 0.1096 - val_acc: 0.9854\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 2.7529e-04 - acc: 1.0000 - val_loss: 0.1096 - val_acc: 0.9853\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 2.7457e-04 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9852\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 2.7407e-04 - acc: 1.0000 - val_loss: 0.1096 - val_acc: 0.9852\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 2.7365e-04 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9853\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 2.7333e-04 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9853\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 2.7305e-04 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9853\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 2.7281e-04 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9853\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 2.7260e-04 - acc: 1.0000 - val_loss: 0.1096 - val_acc: 0.9853\n",
            "Test loss: 0.10955289866334983\n",
            "Test accuracy: 0.9853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoDsuqIyffM",
        "colab_type": "code",
        "outputId": "dd58d31f-5a4b-402c-f203-48d030f5c54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0221 - acc: 0.9954 - val_loss: 0.1221 - val_acc: 0.9812\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0126 - acc: 0.9968 - val_loss: 0.1244 - val_acc: 0.9796\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0125 - acc: 0.9968 - val_loss: 0.1269 - val_acc: 0.9798\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0114 - acc: 0.9970 - val_loss: 0.1201 - val_acc: 0.9801\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.1196 - val_acc: 0.9793\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0089 - acc: 0.9974 - val_loss: 0.1091 - val_acc: 0.9814\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.1136 - val_acc: 0.9806\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0127 - acc: 0.9964 - val_loss: 0.1255 - val_acc: 0.9793\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0142 - acc: 0.9960 - val_loss: 0.0983 - val_acc: 0.9821\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.1013 - val_acc: 0.9812\n",
            "Test loss: 0.10130477977809396\n",
            "Test accuracy: 0.9812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NtYY-P3ylvs",
        "colab_type": "code",
        "outputId": "553a30c3-04e2-41b4-9741-2e05cbe721f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.1091 - val_acc: 0.9844\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 3.6590e-04 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9846\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 3.1034e-04 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9846\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 2.9704e-04 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 0.9847\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 2.8837e-04 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9848\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 2.8205e-04 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9850\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 2.7729e-04 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9852\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 2.7403e-04 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9850\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 2.7184e-04 - acc: 1.0000 - val_loss: 0.1132 - val_acc: 0.9851\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 2.7061e-04 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.9851\n",
            "Test loss: 0.1139764374954947\n",
            "Test accuracy: 0.9851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140675812068096 -->\n<g class=\"node\" id=\"node1\">\n<title>140675812068096</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_1_input: InputLayer</text>\n</g>\n<!-- 140675812505528 -->\n<g class=\"node\" id=\"node2\">\n<title>140675812505528</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 140675812068096&#45;&gt;140675812505528 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140675812068096-&gt;140675812505528</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140675812067312 -->\n<g class=\"node\" id=\"node3\">\n<title>140675812067312</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_2: Dense</text>\n</g>\n<!-- 140675812505528&#45;&gt;140675812067312 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140675812505528-&gt;140675812067312</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140675799067840 -->\n<g class=\"node\" id=\"node4\">\n<title>140675799067840</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 140675812067312&#45;&gt;140675799067840 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140675812067312-&gt;140675799067840</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3a6DTozBS5i",
        "colab_type": "code",
        "outputId": "2a26281e-3ef7-4e37-b220-b9afaeb6dde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMSYoSxDGGGOCsgRhjDEmKEsQxhhjgvr/U2LbWKQr+NIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDrzNdlTJTgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN-m8uTByrY0",
        "colab_type": "code",
        "outputId": "2a9c211f-b7ff-4aa9-910d-68a6bf709edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0462 - acc: 0.9918 - val_loss: 0.1838 - val_acc: 0.9745\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0237 - acc: 0.9942 - val_loss: 0.1337 - val_acc: 0.9797\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 0.0216 - acc: 0.9945 - val_loss: 0.1446 - val_acc: 0.9778\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.0216 - acc: 0.9945 - val_loss: 0.1190 - val_acc: 0.9796\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0190 - acc: 0.9950 - val_loss: 0.1444 - val_acc: 0.9777\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0221 - acc: 0.9944 - val_loss: 0.1170 - val_acc: 0.9799\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0191 - acc: 0.9949 - val_loss: 0.1764 - val_acc: 0.9746\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0187 - acc: 0.9949 - val_loss: 0.1181 - val_acc: 0.9826\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0184 - acc: 0.9953 - val_loss: 0.1281 - val_acc: 0.9777\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0174 - acc: 0.9954 - val_loss: 0.1547 - val_acc: 0.9755\n",
            "Test loss: 0.15473835459180155\n",
            "Test accuracy: 0.9755\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}